# To read data in array from url
import numpy as np
import scipy as sp
from scipy import stats
from StringIO import StringIO
import urllib
url = "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data"
f = urllib.urlopen(url)
data = np.genfromtxt(StringIO(f.read()), delimiter=",")

data.shape # to know the dimensions mxn

# normalizing based on z-score
data[:,0:(data.shape[1]-1)] = stats.zscore(data[:,0:(data.shape[1]-1)])

# randomly shuffle data
np.random.shuffle(data)

# total samples
N = 4601

# split data as 60%, 20%, 20% split
training = data[:int(N*0.6)]
cv = data[int(N*0.6):int(N*0.8)]
test = data[int(N*0.8):]

# fit a model
import scikits as sklearn
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(C=0.1, penalty='l1')
model = lr.fit(training[:,0:-1], training[:,-1)

# test cv set
cv_predict = model.predict(cv[:,0:-1])
cv[:,-1] == cv_predict
cv_result = cv[:,-1] == cv_predict

# status - predicts correctly

# finding mean
for i in range(57):
    print "%s,%s"%(i, sp.mean(data[:, i]))

# finding median
for i in range(57):
    print "%s,%s"%(i, sp.median(data[:, i]))

# finding std
for i in range(57):
    print "%s,%s"%(i, sp.std(data[:, i]))

# plot
mean_data = np.loadtxt("/Users/Harit/Documents/personal/projects/python/machine-learning/mean", delimiter=',')
plot(mean_data)